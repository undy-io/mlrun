# values.yaml
namespace: vllm-services       # Kubernetes namespace
replicaCount: 1               # number of VLLM pods

imageName: docker.io/vllm/vllm-openai
imageVersion: latest

gpu:
  type: amd.com/gpu
  count: 8

model:
  path: Qwen/Qwen3-32B
  name: ''                    # optional model name override
  args: ''                     # additional vllm arguments
  readonly: false
  mountPath: /root/.cache/huggingface
  offline: false

# shared memory size for /dev/shm
sharedMemory: 24Gi

resources:
  limits:
    cpu: 12
    memory: 128Gi
  requests:
    cpu: 12
    memory: 64Gi

borg:
  expose: "default"
